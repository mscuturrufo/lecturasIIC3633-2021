## Evaluating Recommendation Systems

El paper escrito por Shani y Gunawardana (2011) trata basicamente los distintos procesos para evaluar un sistema recomendador. Tipicamente, se tiende a pensar que buen *accuracy* es suficiente para evaluar positivamente a un algoritmo. Sin embargo, aspectos tales como explorar nuevos *items*, preservar la privacidad, rápidez del sistema y más, en ciertos casos, pueden ser  igual de importantes para mejorar la experiencia del usuario. Los autores dividen sus analisis de experimentos en tres tipos: *offline*, *user studies* y *online*. El primer tipo es realizado utilizando data recolectada, por lo que no tiene interacción con usuarios reales. Sin embargo, esta interacción puede proveer información adicional sobre el sistema, y en tales casos se conducen *user studies* donde se observa y registra el comportamiento de ellos. Por otro lado, el experimento que provee la evidencia más real del verdadero valor del sistema es el *online*, donde el *user* real desempeña tareas reales del sistema. En general, el último se utiliza para comparar multiples algoritmos, que puede ser a través de testing A/B, o multiples versiones del mismo algoritmo, con la correción Bonferroni. Posteriormente, el paper describe 14 de las propiedades más comunes consideradas en qué sistema recomendador selecionar.

Lo que más me gustó del paper es que pude responder la pregunta que me surgió en el paper Collaborative Filtering Recommender Systems (2017), leido en la semana 1, en el capitulo *Prediction Accuracy*. Me preguntaba qué analisis existen en términos de sensibilidad y especificidad, por ejemplo, si en estos tipos de sistemas con rating existen tasas de falsos positivos (FP) o falsos negativos (FN). En particular, el actual paper, menciona que esto se reliza en la medición de  *usage prediction*, en donde más que predecir si al *user* le gustará la pelicula, se predice si la verá. El analisis que describe es seleccionar *user* con su lista de selecciones, ocultar algunas y pedirle al recomendador que prediga qué *items* el *user* utilizará. Luego, se tinenen los cuatro resultados posibles: verdaderos positivos, falsos positivos, falsos negativos y verdaderos negativos.
