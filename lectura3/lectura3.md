## Evaluating Recommendation Systems

El paper escrito por Shani y Gunawardana (2011) trata básicamente los distintos procesos para evaluar un sistema recomendador. Típicamente, se tiende a pensar que buen *accuracy* es suficiente para evaluar positivamente a un algoritmo. Sin embargo, aspectos tales como explorar nuevos *items*, preservar la privacidad, rapidez del sistema y más, en ciertos casos, pueden ser  igual de importantes para mejorar la experiencia del usuario. Los autores dividen sus análisis de experimentos en tres tipos: *offline*, *user studies* y *online*. El primer tipo es realizado utilizando data recolectada, por lo que no tiene interacción con usuarios reales. Sin embargo, esta interacción puede proveer información adicional sobre el sistema, y en tales casos se conducen *user studies* donde se observa y registra el comportamiento de ellos. Por otro lado, el experimento que provee la evidencia más real del verdadero valor del sistema es el *online*, donde el *user* real desempeña tareas reales del sistema. En general, el último se utiliza para comparar múltiples algoritmos, que puede ser a través de testing A/B, o múltiples versiones del mismo algoritmo, con la corrección Bonferroni. Posteriormente, el paper describe 14 de las propiedades más comunes consideradas en qué sistema recomendador seleccionar.

Lo que más me gustó del paper es que pude responder la pregunta que me surgió en el paper Collaborative Filtering Recommender Systems (2017), leído en la semana 1, en el capitulo *Prediction Accuracy*. Me preguntaba qué análisis existen en términos de sensibilidad y especificidad. Por ejemplo, si en estos tipos de sistemas con rating existen tasas de falsos positivos (FP) o falsos negativos (FN). En particular, el actual paper, menciona que esto se realiza en la medición de  *usage prediction*, en donde más que predecir si al *user* le gustará la película, se predice si la verá. El análisis que describe es seleccionar *user* con su lista de selecciones, ocultar algunas y pedirle al recomendador que prediga qué *items* el *user* utilizará. Luego, se tienen los cuatro resultados posibles: verdaderos positivos, falsos positivos, falsos negativos y verdaderos negativos. Este método me parece más efectivo que el que planteé anteriormente, de utilizar un *thershold* para el rating predecido, ya que en ciertos casos la retroalimentación más valiosa es que el *user* consuma o no el *item*. Además, al ser un resultado binario, se asemeja más a un problema de clasificación, cuya naturaleza es más acorde a los cuatro resultados anteriores.

De la misma forma, me llamó la atención el capitulo *Robustness* en donde se prueba la estabilidad de la recomendación en la presencia de información falsa, como por ejemplo, a través de *users* falsos que dan buen/mal *rating* a *items* en específicos. No obstante, mientras leía el capitulo no podía dejar de pensar con respecto a los efectos de la cultura de cancelación sobre sistemas recomendadores. Si bien, en ciertos casos, estos no corresponden a información falsa (ej: #metoo) me pregunto: ¿deberían los sistemas recomendadores desarrollar su propia moral? Me refiero a, por ejemplo en los casos de sistemas recomendadores de peliculas, ¿se deberían bajar el *rating* de las peliculas cuyos actores estén involucrados en acusaciones? La verdad es que creo que son preguntas complejas y polémicas de contestar.

En conclusión, además de centrarnos en la gran utilidad de los distintos sistemas recomendadores, es importante conocer las múltiples propiedades de estos para ajustarlos a los requerimientos de los propios proyectos. Finalmente, como se ha visto a lo largo de las distintas lecturas, se deben conocer los diferentes problemas éticos que existen detrás de estos sistemas.  
